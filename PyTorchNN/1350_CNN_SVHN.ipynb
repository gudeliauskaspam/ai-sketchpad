{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks presents **ConvNet** in PyTorch used to solve **Street View House Numbers** task.\n",
    "\n",
    "This is replication of _Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks_\n",
    "\n",
    "**Contents**\n",
    "* [Imports](#Imports)\n",
    "* [Dataset](#Dataset)\n",
    "* [Model](#Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and extract [SVHN](http://ufldl.stanford.edu/housenumbers/) dataset in **Format 1** (train.tar.gz, test.tar.gz, extra.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = '/home/marcin/Datasets/SVHN'  # .../train/1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py  # required to open .mat files in SVHN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = '/home/marcin/Datasets/SVHN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = pathlib.Path(dataset_location)\n",
    "assert os.path.isfile(dataset_path / 'extra/1.png')\n",
    "assert os.path.isfile(dataset_path / 'train/1.png')\n",
    "assert os.path.isfile(dataset_path / 'test/1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to read `.mat` files with labels and bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_name(f, index):\n",
    "    \"\"\"Decode string from HDF5 file.\"\"\"\n",
    "    assert isinstance(f, h5py.File)\n",
    "    assert index == int(index)\n",
    "    ref = f['/digitStruct/name'][index][0]\n",
    "    return ''.join(chr(v[0]) for v in f[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_digits_raw(f, index):\n",
    "    \"\"\"Decode digits and bounding boxes from HDF5 file.\"\"\"\n",
    "    assert isinstance(f, h5py.File)\n",
    "    assert index == int(index)\n",
    "    \n",
    "    ref = f['/digitStruct/bbox'][index].item()\n",
    "    ddd = {}\n",
    "    for key in ['label', 'left', 'top', 'width', 'height']:\n",
    "        dset = f[ref][key]\n",
    "        if len(dset) == 1:\n",
    "            ddd[key] = [ int(dset[0][0]) ]\n",
    "        else:\n",
    "            ddd[key] = []\n",
    "            for i in range(len(dset)):\n",
    "                ref2 = dset[i][0]\n",
    "                ddd[key].append( int(f[ref2][0][0]) )\n",
    "    return ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(ddict):\n",
    "    \"\"\"Convert raw digit info into len-5 label and single bounding box\"\"\"\n",
    "    assert isinstance(ddict, dict)\n",
    "    \n",
    "    # construct proper label for NN training\n",
    "    # image '210' -> [3, 2, 1, 10, 0, 0]\n",
    "    #                 ^  ^  ^  ^   ^--^-- \"0, 0\" pad with '0' (no digit)\n",
    "    #                 |  ---------------- \"210\" house number, 0 encoded as 10\n",
    "    #                 ------------------- \"3\" is number of digits\n",
    "    label = ddict['label'].copy()\n",
    "    label = [len(label)] + label + [0]*(5-len(label))\n",
    "    \n",
    "    left = min(ddict['left'])\n",
    "    top = min(ddict['top'])\n",
    "    right = max(l+w for l, w in zip(ddict['left'], ddict['width']))\n",
    "    bottom = max(t+h for t, h in zip(ddict['top'], ddict['height']))\n",
    "    return tuple(label), (left, top, right, bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mat_file(filepath):\n",
    "    \"\"\"Open .mat file and read all the metadata.\"\"\"\n",
    "    assert isinstance(filepath, (str, pathlib.PosixPath))\n",
    "    \n",
    "    print(filepath)\n",
    "    \n",
    "    meta = {'names':[], 'labels':[], 'bboxes':[]}\n",
    "    with h5py.File(filepath) as f:\n",
    "        length = len(f['/digitStruct/name'])\n",
    "        for i in range(10): # length):\n",
    "            name = read_name(f, i)\n",
    "            ddict = read_digits_raw(f, i)\n",
    "            label, bbox = get_label(ddict)\n",
    "            meta['names'].append(name)\n",
    "            meta['labels'].append(label)\n",
    "            meta['bboxes'].append(bbox)\n",
    "            if i % 1000 == 0 or i == length-1:\n",
    "                print(f'{i:6d} / {length}')\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_or_generate(name):\n",
    "    \"\"\"Either load .pkl, or if doesn't exit generate it and open.\"\"\"\n",
    "    assert name in ('extra', 'test', 'train')\n",
    "    \n",
    "    fname = name+'.pkl'\n",
    "    if os.path.exists(dataset_path / fname):\n",
    "        with open(dataset_path / fname, 'rb') as f:\n",
    "            meta = pickle.load(f)\n",
    "            print(f'Loaded:{fname}')\n",
    "    else:\n",
    "        print(f'Generating {fname}:')\n",
    "        meta = read_mat_file(dataset_path / name / 'digitStruct.mat')\n",
    "        with open(dataset_path / fname, 'wb') as f:\n",
    "            pickle.dump(meta, f)\n",
    "    \n",
    "    return meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** this may take <u>several minutes</u> first time it's run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:test.pkl\n"
     ]
    }
   ],
   "source": [
    "#extra_meta = open_or_generate('extra')\n",
    "test_meta = open_or_generate('test')\n",
    "#train_meta = open_or_generate('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset: #(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_folder, metadata, transforms=None):\n",
    "        assert isinstance(image_folder, (str, pathlib.PosixPath))\n",
    "        assert isinstance(metadata, dict)\n",
    "        assert set(metadata.keys()) == {'bboxes', 'labels', 'names'}\n",
    "        assert len(metadata['names']) == len(metadata['labels'])\n",
    "        assert len(metadata['names']) == len(metadata['bboxes'])\n",
    "        assert transforms is None or \\\n",
    "               isinstance(transforms, torchvision.transforms.Compose)\n",
    "        \n",
    "        self.image_folder = pathlib.PosixPath(image_folder)\n",
    "        self.metadata = metadata\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.metadata['names'][index]  # '1.png'\n",
    "        label = self.metadata['labels'][index]       # [1, 2, 10, 0, 0]\n",
    "        bbox = self.metadata['bboxes'][index]         # [left, top, right, bot.]\n",
    "        \n",
    "        # Figure out crop box\n",
    "        left, top, right, bottom = bbox\n",
    "        width, height = right - left, bottom - top\n",
    "        crop_left =   int(round(left   - .15*width))\n",
    "        crop_top =    int(round(top    - .15*height))\n",
    "        crop_right =  int(round(right  + .15*width))\n",
    "        crop_bottom = int(round(bottom + .15*height))\n",
    "        \n",
    "        img = PIL.Image.open(self.image_folder / image_name)\n",
    "        img2 = img.crop(box=(crop_left, crop_top, crop_right, crop_bottom))\n",
    "        res = img2.resize((64, 64))\n",
    "        if self.transforms is not None:\n",
    "            res = self.transforms(res)\n",
    "        \n",
    "        return res, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SVHNDataset(dataset_path / 'test', test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = dataset[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F88102DC5F8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 5, 0, 0, 0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:svhn]",
   "language": "python",
   "name": "conda-env-svhn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
