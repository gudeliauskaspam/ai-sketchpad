{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks presents **something** in Framework to solve **A Problem**.\n",
    "\n",
    "**Contents**\n",
    "* [Imports](#Imports)\n",
    "* [Dataset](#Dataset)\n",
    "* [Model](#Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**References**\n",
    "* [Deep Residual Learning for Image Recognition]() (2015) by Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = '/home/user/datasets/catsdogs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)  # init TF ...\n",
    "config=tf.ConfigProto(gpu_options=gpu_options)  # w/o taking ...\n",
    "with tf.Session(config=config): pass            # all GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* read raw data\n",
    "  * drop, convert, etc.\n",
    "* preprocessing\n",
    "  * encoding (one-hot)\n",
    "  * normalise\n",
    "  * split train/valid\n",
    "  * split features/targets\n",
    "* data loaders\n",
    "* (optional) save processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess (opt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* e.g. NLP preprocessing, "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (optional) load processed data\n",
    "  * push to GPU\n",
    "* define model/loss\n",
    "* callbacks\n",
    "  * schedulers\n",
    "  * tensorboard\n",
    "  * checkpoints\n",
    "* train loop\n",
    "* evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1 (opt.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* if many experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* any unit testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick GPU if available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_in, n_hid, n_out):\n",
    "        super().__init__()          # !\n",
    "        self.fc1 = nn.Linear(in_features=n_in, out_features=n_hid)\n",
    "        self.fc2 = nn.Linear(in_features=n_hid, out_features=n_out)\n",
    "    \n",
    "    def forward(self, x):           # [n_batch, n_in]\n",
    "        x = self.fc1(x)             # [n_batch, n_hid]\n",
    "        x = self.fc2(x)             # [n_batch, n_out]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantinate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CharRNN(nb_layers, n_in, n_embed, n_hid, n_out, dropout)\n",
    "model.to(device)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1000\n",
    "hist = { 'epoch': 0,\n",
    "         'train_loss':[], 'train_accuracy':[],\n",
    "         'valid_loss':[], 'valid_accuracy':[]\n",
    "       }\n",
    "\n",
    "def train(hist, nb_epochs, train_dl, valid_dl):\n",
    "    \n",
    "    for _ in range(nb_epochs):\n",
    "        epoch = hist['epoch']\n",
    "        \n",
    "        ### Train ###\n",
    "        model.train()\n",
    "        loss_sum, accuracy_sum = 0, 0\n",
    "        for features, targets in train_dl:\n",
    "            \n",
    "            # Push to GPU\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Optimize\n",
    "            outputs = model(features)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                acc = accuracy(outputs, targets)\n",
    "                loss_sum += loss.item()\n",
    "                accuracy_sum += acc.item()\n",
    "                hist['iter_epoch'].append( epoch )\n",
    "                hist['iter_accuracy'].append( acc.item() )\n",
    "                hist['iter_loss'].append( loss.item() )\n",
    "        \n",
    "        hist['train_loss'].append( loss_sum / len(train_dl) )\n",
    "        hist['train_accuracy'].append( accuracy_sum / len(train_dl) )\n",
    "        \n",
    "        ### Evaluate ###\n",
    "        model.eval()\n",
    "        loss_sum, accuracy_sum = 0, 0\n",
    "        for features, targets in valid_dl:\n",
    "            \n",
    "            # Push to GPU\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            # Eval\n",
    "            with torch.no_grad():\n",
    "                outputs = model(features)\n",
    "                loss = criterion(outputs, targets)\n",
    "                acc = accuracy(outputs, targets)\n",
    "                \n",
    "                loss_sum += loss.item()\n",
    "                accuracy_sum += acc.item()\n",
    "        \n",
    "        hist['valid_loss'].append( loss_sum / len(train_dl) )\n",
    "        hist['valid_accuracy'].append( accuracy_sum / len(train_dl) )\n",
    "        \n",
    "        ### Print Summary ###\n",
    "        if epoch == 0:\n",
    "            print('      (time )   ep             Loss (t/v)                Acc (t/v)')\n",
    "        print(f'Epoch ({epoch_time_interval:4.2}s): {epoch:3}'\n",
    "              f'    {hist[\"train_loss\"][-1]:6.4f} / {hist[\"valid_loss\"][-1]:6.4f}'\n",
    "              f'    {hist[\"train_acc\"][-1]:6.4f} / {hist[\"valid_acc\"][-1]:6.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomSequence(tf.keras.utils.Sequence):\n",
    "\n",
    "    def __init__(self, features, targets, batch_size, shuffle=False):\n",
    "        self.features = features\n",
    "        self.targets = targets\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.features) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_indices = self.indices[idx * self.batch_size :\n",
    "                                     (idx+1) * self.batch_size]\n",
    "        batch_features = self.features[batch_i]\n",
    "        batch_targets = self.targets[batch_i]\n",
    "\n",
    "        return batch_features, batch_targets\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        self.indices = np.arange(len(self.data_x))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CallbackPlot(tf.keras.callbacks.Callback):\n",
    "    def __init__(self, train_images, valid_images):\n",
    "        self.train_images = train_images\n",
    "        self.valid_images = valid_images\n",
    "    \n",
    "    def on_train_begin(self, logs={}):\n",
    "        pass\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        _, iw, ih, _ = self.train_images.shape\n",
    "        \n",
    "        predictions = model.predict(self.train_images)\n",
    "        plot_images([5, 10, 15, 20, 25, 30],\n",
    "                    undo_preprocess_images(self.train_images),\n",
    "                    undo_preprocess_keypts(predictions, iw))\n",
    "        \n",
    "        predictions = model.predict(self.valid_images)\n",
    "        plot_images([5, 10, 15, 20, 25, 30],\n",
    "                    undo_preprocess_images(self.valid_images),\n",
    "                    undo_preprocess_keypts(predictions, iw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit_generator(train_generator,\n",
    "                           epochs=20,\n",
    "                           validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
