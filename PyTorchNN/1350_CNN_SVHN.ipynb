{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks presents **ConvNet** in PyTorch used to solve **Street View House Numbers** task.\n",
    "\n",
    "This is replication of _Multi-digit Number Recognition from Street View Imagery using Deep Convolutional Neural Networks_\n",
    "\n",
    "**Contents**\n",
    "* [Imports](#Imports)\n",
    "* [Dataset](#Dataset)\n",
    "* [Model](#Model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download and extract [SVHN](http://ufldl.stanford.edu/housenumbers/) dataset in **Format 1** (train.tar.gz, test.tar.gz, extra.tar.gz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = '/home/marcin/Datasets/SVHN'  # .../train/1.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import pathlib\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py  # required to open .mat files in SVHN dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import PIL.Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_location = '/home/marcin/Datasets/SVHN'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = pathlib.Path(dataset_location)\n",
    "assert os.path.isfile(dataset_path / 'extra/1.png')\n",
    "assert os.path.isfile(dataset_path / 'train/1.png')\n",
    "assert os.path.isfile(dataset_path / 'test/1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions to read `.mat` files with labels and bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_name(f, index):\n",
    "    \"\"\"Decode string from HDF5 file.\"\"\"\n",
    "    assert isinstance(f, h5py.File)\n",
    "    assert index == int(index)\n",
    "    ref = f['/digitStruct/name'][index][0]\n",
    "    return ''.join(chr(v[0]) for v in f[ref])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_digits_raw(f, index):\n",
    "    \"\"\"Decode digits and bounding boxes from HDF5 file.\"\"\"\n",
    "    assert isinstance(f, h5py.File)\n",
    "    assert index == int(index)\n",
    "    \n",
    "    ref = f['/digitStruct/bbox'][index].item()\n",
    "    ddd = {}\n",
    "    for key in ['label', 'left', 'top', 'width', 'height']:\n",
    "        dset = f[ref][key]\n",
    "        if len(dset) == 1:\n",
    "            ddd[key] = [ int(dset[0][0]) ]\n",
    "        else:\n",
    "            ddd[key] = []\n",
    "            for i in range(len(dset)):\n",
    "                ref2 = dset[i][0]\n",
    "                ddd[key].append( int(f[ref2][0][0]) )\n",
    "    return ddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(ddict):\n",
    "    \"\"\"Convert raw digit info into len-5 label and single bounding box\"\"\"\n",
    "    assert isinstance(ddict, dict)\n",
    "    \n",
    "    # construct proper label for NN training\n",
    "    # image '210' -> [3, 2, 1, 10, 0, 0]\n",
    "    #                 ^  ^  ^  ^   ^--^-- \"0, 0\" pad with '0' (no digit)\n",
    "    #                 |  ---------------- \"210\" house number, 0 encoded as 10\n",
    "    #                 ------------------- \"3\" is number of digits\n",
    "    label = ddict['label'].copy()\n",
    "    label = [len(label)] + label + [0]*(5-len(label))\n",
    "    \n",
    "    left = min(ddict['left'])\n",
    "    top = min(ddict['top'])\n",
    "    right = max(l+w for l, w in zip(ddict['left'], ddict['width']))\n",
    "    bottom = max(t+h for t, h in zip(ddict['top'], ddict['height']))\n",
    "    return tuple(label), (left, top, right, bottom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mat_file(filepath):\n",
    "    \"\"\"Open .mat file and read all the metadata.\"\"\"\n",
    "    assert isinstance(filepath, (str, pathlib.PosixPath))\n",
    "    \n",
    "    print(filepath)\n",
    "    \n",
    "    meta = {'names':[], 'labels':[], 'bboxes':[]}\n",
    "    with h5py.File(filepath) as f:\n",
    "        length = len(f['/digitStruct/name'])\n",
    "        for i in range(10): # length):\n",
    "            name = read_name(f, i)\n",
    "            ddict = read_digits_raw(f, i)\n",
    "            label, bbox = get_label(ddict)\n",
    "            meta['names'].append(name)\n",
    "            meta['labels'].append(label)\n",
    "            meta['bboxes'].append(bbox)\n",
    "            if i % 1000 == 0 or i == length-1:\n",
    "                print(f'{i:6d} / {length}')\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_or_generate(name):\n",
    "    \"\"\"Either load .pkl, or if doesn't exit generate it and open.\"\"\"\n",
    "    assert name in ('extra', 'test', 'train')\n",
    "    \n",
    "    fname = name+'.pkl'\n",
    "    if os.path.exists(dataset_path / fname):\n",
    "        with open(dataset_path / fname, 'rb') as f:\n",
    "            meta = pickle.load(f)\n",
    "            print(f'Loaded:{fname}')\n",
    "    else:\n",
    "        print(f'Generating {fname}:')\n",
    "        meta = read_mat_file(dataset_path / name / 'digitStruct.mat')\n",
    "        with open(dataset_path / fname, 'wb') as f:\n",
    "            pickle.dump(meta, f)\n",
    "    \n",
    "    return meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** this may take <u>several minutes</u> first time it's run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded:test.pkl\n"
     ]
    }
   ],
   "source": [
    "#extra_meta = open_or_generate('extra')\n",
    "test_meta = open_or_generate('test')\n",
    "#train_meta = open_or_generate('train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVHNDataset: #(torch.utils.data.Dataset):\n",
    "    def __init__(self, image_folder, metadata, transforms=None):\n",
    "        assert isinstance(image_folder, (str, pathlib.PosixPath))\n",
    "        assert isinstance(metadata, dict)\n",
    "        assert set(metadata.keys()) == {'bboxes', 'labels', 'names'}\n",
    "        assert len(metadata['names']) == len(metadata['labels'])\n",
    "        assert len(metadata['names']) == len(metadata['bboxes'])\n",
    "        assert transforms is None or \\\n",
    "               isinstance(transforms, torchvision.transforms.Compose)\n",
    "        \n",
    "        self.image_folder = pathlib.PosixPath(image_folder)\n",
    "        self.metadata = metadata\n",
    "        self.transforms = transforms\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(image_paths)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_name = self.metadata['names'][index]  # '1.png'\n",
    "        label = self.metadata['labels'][index]       # [1, 2, 10, 0, 0]\n",
    "        bbox = self.metadata['bboxes'][index]         # [left, top, right, bot.]\n",
    "        \n",
    "        # Figure out crop box\n",
    "        left, top, right, bottom = bbox\n",
    "        width, height = right - left, bottom - top\n",
    "        crop_left =   int(round(left   - .15*width))\n",
    "        crop_top =    int(round(top    - .15*height))\n",
    "        crop_right =  int(round(right  + .15*width))\n",
    "        crop_bottom = int(round(bottom + .15*height))\n",
    "        \n",
    "        img = PIL.Image.open(self.image_folder / image_name)\n",
    "        img2 = img.crop(box=(crop_left, crop_top, crop_right, crop_bottom))\n",
    "        res = img2.resize((64, 64))\n",
    "        if self.transforms is not None:\n",
    "            res = self.transforms(res)\n",
    "        \n",
    "        return res, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SVHNDataset(dataset_path / 'test', test_meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, label = dataset[13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=64x64 at 0x7F88102DC5F8>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2, 5, 0, 0, 0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class SVHNModel(torch.nn.Module):\n",
    "    \n",
    "    def _block(in_channels, out_channels, stride):\n",
    "        \"\"\"Helper to build CNN blocks.\"\"\"\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n",
    "                      kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(num_features=out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=stride, padding=1),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.block1 = _block(in_channels=  3, out_channels= 48, stride=2)\n",
    "        self.block2 = _block(in_channels= 48, out_channels= 64, stride=1)\n",
    "        self.block3 = _block(in_channels= 64, out_channels=128, stride=2)\n",
    "        self.block4 = _block(in_channels=128, out_channels=160, stride=1)\n",
    "        self.block5 = _block(in_channels=160, out_channels=192, stride=2)\n",
    "        self.block6 = _block(in_channels=192, out_channels=192, stride=1)\n",
    "        self.block7 = _block(in_channels=192, out_channels=192, stride=2)\n",
    "        self.block8 = _block(in_channels=192, out_channels=192, stride=1)\n",
    "        self.fc1 = nn.Sequential(nn.Linear(192 * 7 * 7, 3072), nn.ReLU())\n",
    "        self.fc2 = nn.Sequential(nn.Linear(3072, 3072), nn.ReLU())\n",
    "        \n",
    "        self.length = nn.Sequential(nn.Linear(3072, 7))\n",
    "        self.digit1 = nn.Sequential(nn.Linear(3072, 11))\n",
    "        self.digit2 = nn.Sequential(nn.Linear(3072, 11))\n",
    "        self.digit3 = nn.Sequential(nn.Linear(3072, 11))\n",
    "        self.digit4 = nn.Sequential(nn.Linear(3072, 11))\n",
    "        self.digit5 = nn.Sequential(nn.Linear(3072, 11))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.block4(x)\n",
    "        x = self.block5(x)\n",
    "        x = self.block6(x)\n",
    "        x = self.block7(x)\n",
    "        x = self.block8(x)\n",
    "        x = x.view(x.size(0), 192*7*7)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        length = self.length(x)  #  logits!\n",
    "        digit1 = self.digit1(x)\n",
    "        digit2 = self.digit2(x)\n",
    "        digit3 = self.digit3(x)\n",
    "        digit4 = self.digit4(x)\n",
    "        digit5 = self.digit5(x)\n",
    "        \n",
    "        return length, digit1, digit2, digit3, digit4, digit5    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVHNModel(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(3, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.2)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.2)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.2)\n",
       "  )\n",
       "  (block4): Sequential(\n",
       "    (0): Conv2d(128, 160, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.2)\n",
       "  )\n",
       "  (block5): Sequential(\n",
       "    (0): Conv2d(160, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.2)\n",
       "  )\n",
       "  (block6): Sequential(\n",
       "    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.2)\n",
       "  )\n",
       "  (block7): Sequential(\n",
       "    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.2)\n",
       "  )\n",
       "  (block8): Sequential(\n",
       "    (0): Conv2d(192, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): MaxPool2d(kernel_size=2, stride=1, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Dropout(p=0.2)\n",
       "  )\n",
       "  (fc1): Sequential(\n",
       "    (0): Linear(in_features=9408, out_features=3072, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (fc2): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=3072, bias=True)\n",
       "    (1): ReLU()\n",
       "  )\n",
       "  (length): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=7, bias=True)\n",
       "  )\n",
       "  (digit1): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=11, bias=True)\n",
       "  )\n",
       "  (digit2): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=11, bias=True)\n",
       "  )\n",
       "  (digit3): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=11, bias=True)\n",
       "  )\n",
       "  (digit4): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=11, bias=True)\n",
       "  )\n",
       "  (digit5): Sequential(\n",
       "    (0): Linear(in_features=3072, out_features=11, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SVHNModel()\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 48, 54, 54]           3,648\n",
      "       BatchNorm2d-2           [-1, 48, 54, 54]              96\n",
      "              ReLU-3           [-1, 48, 54, 54]               0\n",
      "         MaxPool2d-4           [-1, 48, 28, 28]               0\n",
      "           Dropout-5           [-1, 48, 28, 28]               0\n",
      "            Conv2d-6           [-1, 64, 28, 28]          76,864\n",
      "       BatchNorm2d-7           [-1, 64, 28, 28]             128\n",
      "              ReLU-8           [-1, 64, 28, 28]               0\n",
      "         MaxPool2d-9           [-1, 64, 29, 29]               0\n",
      "          Dropout-10           [-1, 64, 29, 29]               0\n",
      "           Conv2d-11          [-1, 128, 29, 29]         204,928\n",
      "      BatchNorm2d-12          [-1, 128, 29, 29]             256\n",
      "             ReLU-13          [-1, 128, 29, 29]               0\n",
      "        MaxPool2d-14          [-1, 128, 15, 15]               0\n",
      "          Dropout-15          [-1, 128, 15, 15]               0\n",
      "           Conv2d-16          [-1, 160, 15, 15]         512,160\n",
      "      BatchNorm2d-17          [-1, 160, 15, 15]             320\n",
      "             ReLU-18          [-1, 160, 15, 15]               0\n",
      "        MaxPool2d-19          [-1, 160, 16, 16]               0\n",
      "          Dropout-20          [-1, 160, 16, 16]               0\n",
      "           Conv2d-21          [-1, 192, 16, 16]         768,192\n",
      "      BatchNorm2d-22          [-1, 192, 16, 16]             384\n",
      "             ReLU-23          [-1, 192, 16, 16]               0\n",
      "        MaxPool2d-24            [-1, 192, 9, 9]               0\n",
      "          Dropout-25            [-1, 192, 9, 9]               0\n",
      "           Conv2d-26            [-1, 192, 9, 9]         921,792\n",
      "      BatchNorm2d-27            [-1, 192, 9, 9]             384\n",
      "             ReLU-28            [-1, 192, 9, 9]               0\n",
      "        MaxPool2d-29          [-1, 192, 10, 10]               0\n",
      "          Dropout-30          [-1, 192, 10, 10]               0\n",
      "           Conv2d-31          [-1, 192, 10, 10]         921,792\n",
      "      BatchNorm2d-32          [-1, 192, 10, 10]             384\n",
      "             ReLU-33          [-1, 192, 10, 10]               0\n",
      "        MaxPool2d-34            [-1, 192, 6, 6]               0\n",
      "          Dropout-35            [-1, 192, 6, 6]               0\n",
      "           Conv2d-36            [-1, 192, 6, 6]         921,792\n",
      "      BatchNorm2d-37            [-1, 192, 6, 6]             384\n",
      "             ReLU-38            [-1, 192, 6, 6]               0\n",
      "        MaxPool2d-39            [-1, 192, 7, 7]               0\n",
      "          Dropout-40            [-1, 192, 7, 7]               0\n",
      "           Linear-41                 [-1, 3072]      28,904,448\n",
      "             ReLU-42                 [-1, 3072]               0\n",
      "           Linear-43                 [-1, 3072]       9,440,256\n",
      "             ReLU-44                 [-1, 3072]               0\n",
      "           Linear-45                    [-1, 7]          21,511\n",
      "           Linear-46                   [-1, 11]          33,803\n",
      "           Linear-47                   [-1, 11]          33,803\n",
      "           Linear-48                   [-1, 11]          33,803\n",
      "           Linear-49                   [-1, 11]          33,803\n",
      "           Linear-50                   [-1, 11]          33,803\n",
      "================================================================\n",
      "Total params: 42,868,734\n",
      "Trainable params: 42,868,734\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.03\n",
      "Forward/backward pass size (MB): 13.05\n",
      "Params size (MB): 163.53\n",
      "Estimated Total Size (MB): 176.62\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(3, 54, 54))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:svhn]",
   "language": "python",
   "name": "conda-env-svhn-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
